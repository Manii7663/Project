{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_connection_string =  \"mongodb+srv://manii:1234@cluster0.bditt1m.mongodb.net/project?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "# Snowflake connection settings\n",
    "SNOWFLAKE_ACCOUNT = \"lx16664.central-india.azure\"\n",
    "SNOWFLAKE_USER = \"mani\"\n",
    "SNOWFLAKE_PASSWORD = \"Jman@600113\"\n",
    "SNOWFLAKE_DATABASE = \"TrainingProject\"\n",
    "SNOWFLAKE_SCHEMA = \"PROJECT_MART\"\n",
    "SNOWFLAKE_WAREHOUSE = \"COMPUTE_WH\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to Snowflake using environment variables\n",
    "\n",
    "\n",
    "    conn = snowflake.connector.connect(\n",
    "    user=SNOWFLAKE_USER,\n",
    "    password=SNOWFLAKE_PASSWORD,\n",
    "    account=SNOWFLAKE_ACCOUNT,\n",
    "    warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "    database=SNOWFLAKE_DATABASE,\n",
    "    schema=SNOWFLAKE_SCHEMA\n",
    ")\n",
    "\n",
    "    # Print connection success message\n",
    "    print(\"Connected to Snowflake successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with snowflake_conn\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to Snowflake: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "\n",
    "# Execute SQL query to fetch data\n",
    "sql_query = f\"SELECT * FROM MART_TRAINING_KPI\"\n",
    "cur.execute(sql_query)\n",
    "\n",
    "# Fetch data into a pandas DataFrame\n",
    "data = cur.fetchall()\n",
    "columns = [col[0] for col in cur.description]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Close cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 13)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROGRAMNAME', 'TOTAL_TRAINERS', 'TOTAL_SESSIONS', 'TOTAL_HOURS',\n",
       "       'TOTAL_DAYS', 'AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION',\n",
       "       'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE',\n",
       "       'AVG_SCORE', 'MAX_SCORE', 'MIN_SCORE', 'ASSESSMENT_COUNT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['PROGRAMNAME', 'TOTAL_TRAINERS', 'TOTAL_DAYS', 'AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SSSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE', 'AVG_SCORE', 'MAX_SCORE', 'MIN_SCORE', 'ASSESSMENT_COUNT', 'TOTAL_HOURS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAMNAME</th>\n",
       "      <th>TOTAL_TRAINERS</th>\n",
       "      <th>TOTAL_DAYS</th>\n",
       "      <th>AVERAGE_HOURS_PER_SESSION</th>\n",
       "      <th>AVERAGE_DAYS_PER_SESSION</th>\n",
       "      <th>AVERAGE_COMPLETED_PERCENTAGE</th>\n",
       "      <th>AVERAGE_PENDING_PERCENTAGE</th>\n",
       "      <th>AVG_SCORE</th>\n",
       "      <th>MAX_SCORE</th>\n",
       "      <th>MIN_SCORE</th>\n",
       "      <th>ASSESSMENT_COUNT</th>\n",
       "      <th>TOTAL_HOURS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Fundamentals</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advanced Machine Learning</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UI/UX Design Essentials</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Backend Development Bootcamp</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cloud Computing Fundamentals</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    PROGRAMNAME  TOTAL_TRAINERS  TOTAL_DAYS  \\\n",
       "0     Data Science Fundamentals               1         2.0   \n",
       "1     Advanced Machine Learning               1         7.0   \n",
       "2       UI/UX Design Essentials               1         3.0   \n",
       "3  Backend Development Bootcamp               1         4.0   \n",
       "4  Cloud Computing Fundamentals               1         9.0   \n",
       "\n",
       "   AVERAGE_HOURS_PER_SESSION  AVERAGE_DAYS_PER_SESSION  \\\n",
       "0                       16.0                       2.0   \n",
       "1                       56.0                       7.0   \n",
       "2                       24.0                       3.0   \n",
       "3                       32.0                       4.0   \n",
       "4                       24.0                       3.0   \n",
       "\n",
       "   AVERAGE_COMPLETED_PERCENTAGE  AVERAGE_PENDING_PERCENTAGE  AVG_SCORE  \\\n",
       "0                         100.0                         0.0       81.0   \n",
       "1                         100.0                         0.0       81.0   \n",
       "2                         100.0                         0.0       37.0   \n",
       "3                         100.0                         0.0       84.0   \n",
       "4                         100.0                         0.0       73.0   \n",
       "\n",
       "   MAX_SCORE  MIN_SCORE  ASSESSMENT_COUNT  TOTAL_HOURS  \n",
       "0       81.0       81.0               1.0         16.0  \n",
       "1       81.0       81.0               1.0         56.0  \n",
       "2       37.0       37.0               1.0         24.0  \n",
       "3       84.0       84.0               1.0         32.0  \n",
       "4       93.0       33.0               3.0         72.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[selected_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value count per column:\n",
      "PROGRAMNAME                      0\n",
      "TOTAL_TRAINERS                   0\n",
      "TOTAL_DAYS                      18\n",
      "AVERAGE_HOURS_PER_SESSION       18\n",
      "AVERAGE_DAYS_PER_SESSION        18\n",
      "AVERAGE_COMPLETED_PERCENTAGE    18\n",
      "AVERAGE_PENDING_PERCENTAGE      18\n",
      "AVG_SCORE                       18\n",
      "MAX_SCORE                       18\n",
      "MIN_SCORE                       18\n",
      "ASSESSMENT_COUNT                18\n",
      "TOTAL_HOURS                     18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "\n",
    "print(\"Null value count per column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value count per column after filling with averages and converting to int:\n",
      "PROGRAMNAME                      0\n",
      "TOTAL_TRAINERS                   0\n",
      "TOTAL_DAYS                       0\n",
      "AVERAGE_HOURS_PER_SESSION       18\n",
      "AVERAGE_DAYS_PER_SESSION        18\n",
      "AVERAGE_COMPLETED_PERCENTAGE     0\n",
      "AVERAGE_PENDING_PERCENTAGE       0\n",
      "AVG_SCORE                        0\n",
      "MAX_SCORE                        0\n",
      "MIN_SCORE                        0\n",
      "ASSESSMENT_COUNT                 0\n",
      "TOTAL_HOURS                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specify the columns with null values\n",
    "columns_with_null = ['TOTAL_DAYS',\n",
    "                     'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE', 'AVG_SCORE',\n",
    "                     'MAX_SCORE', 'MIN_SCORE', 'ASSESSMENT_COUNT', 'TOTAL_HOURS']\n",
    "\n",
    "# Calculate the average of each specified column\n",
    "column_means = df[columns_with_null].mean()\n",
    "\n",
    "# Fill null values in specified columns with the average of each column\n",
    "df[columns_with_null] = df[columns_with_null].fillna(column_means)\n",
    "\n",
    "# Convert specified columns to integer type\n",
    "df[columns_with_null] = df[columns_with_null].astype(int)\n",
    "\n",
    "# Check if any null values remain\n",
    "null_counts_after_fill = df.isnull().sum()\n",
    "\n",
    "print(\"Null value count per column after filling with averages and converting to int:\")\n",
    "print(null_counts_after_fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-52db9670cef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Separate features and target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PROGRAMNAME'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TOTAL_TRAINERS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TOTAL_DAYS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AVERAGE_HOURS_PER_SESSION'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AVERAGE_DAYS_PER_SESSION'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AVERAGE_COMPLETED_PERCENTAGE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AVERAGE_PENDING_PERCENTAGE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AVG_SCORE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MAX_SCORE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MIN_SCORE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ASSESSMENT_COUNT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TOTAL_HOURS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5780\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5782\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5784\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5844\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5845\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5847\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Assume df1 is your preprocessed DataFrame with features and target column 'SCOREACHIEVEDINQUIZ'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[ ['PROGRAMNAME', 'TOTAL_TRAINERS', 'TOTAL_DAYS', 'AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE','AVG_SCORE','MAX_SCORE','MIN_SCORE','ASSESSMENT_COUNT']]\n",
    "y = df['TOTAL_HOURS']\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Handle NaN values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X_encoded), columns=X_encoded.columns)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42),\n",
    "    'Support Vector Regressor': SVR(),\n",
    "    'Neural Network (MLPRegressor)': MLPRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{name}: Mean Squared Error = {mse}\")\n",
    "\n",
    "# You can also perform cross-validation to get more reliable estimates of model performance\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_imputed, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_mean = -scores.mean()\n",
    "    print(f\"{name}: Cross-validated Mean Squared Error = {mse_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-6c17fdfb2ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Separate features and target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PROGRAMNAME'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TOTAL_TRAINERS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TOTAL_DAYS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AVERAGE_HOURS_PER_SESSION'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AVERAGE_DAYS_PER_SESSION'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AVERAGE_COMPLETED_PERCENTAGE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AVERAGE_PENDING_PERCENTAGE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AVG_SCORE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MAX_SCORE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MIN_SCORE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ASSESSMENT_COUNT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TOTAL_HOURS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5780\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5782\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5784\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5844\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5845\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5847\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[ ['PROGRAMNAME', 'TOTAL_TRAINERS', 'TOTAL_DAYS', 'AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE','AVG_SCORE','MAX_SCORE','MIN_SCORE','ASSESSMENT_COUNT']]\n",
    "y = df['TOTAL_HOURS']\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = pd.get_dummies(X)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Handle NaN values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X_encoded), columns=X_encoded.columns)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = linear_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "threshold = 2\n",
    "\n",
    "# Convert regression predictions to binary classification labels\n",
    "y_pred_binary = (y_pred <= threshold).astype(int)\n",
    "y_test_binary = (y_test <= threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy for binary classification\n",
    "accuracy = (y_pred_binary == y_test_binary).mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Completion Time: 13 hrs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define dummy values for features\n",
    "dummy_data = {\n",
    "    'PROGRAMNAME': ['Program A'],\n",
    "    'TOTAL_TRAINERS': [5],\n",
    "    'TOTAL_DAYS': [20],\n",
    "    'AVERAGE_HOURS_PER_SESSION': [2.5],\n",
    "    'AVERAGE_DAYS_PER_SESSION': [1.5],\n",
    "    'AVERAGE_COMPLETED_PERCENTAGE': [80],\n",
    "    'AVERAGE_PENDING_PERCENTAGE': [20],\n",
    "    'AVG_SCORE': [85],\n",
    "    'MAX_SCORE': [100],\n",
    "    'MIN_SCORE': [60],\n",
    "    'ASSESSMENT_COUNT': [50]\n",
    "}\n",
    "\n",
    "\n",
    "# Create DataFrame with dummy values\n",
    "dummy_df = pd.DataFrame(dummy_data)\n",
    "\n",
    "# Get the list of feature names used during training\n",
    "training_feature_names = X_imputed.columns.tolist()\n",
    "\n",
    "# Ensure that the dummy DataFrame has the same columns as training data\n",
    "dummy_df = pd.get_dummies(dummy_df)\n",
    "dummy_df = dummy_df.reindex(columns=training_feature_names, fill_value=0)\n",
    "\n",
    "# Handle NaN values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "dummy_imputed = pd.DataFrame(imputer.fit_transform(dummy_df), columns=dummy_df.columns)\n",
    "\n",
    "# Make prediction\n",
    "prediction = linear_regressor.predict(dummy_imputed)\n",
    "\n",
    "# Print prediction\n",
    "print(\"Predicted Completion Time:\", int(prediction[0]) ,'hrs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AVERAGE_COMPLETED_PERCENTAGE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d8d443ac53ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m'TOTAL_DAYS'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;34m'AVERAGE_COMPLETED_PERCENTAGE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;34m'AVERAGE_PENDING_PERCENTAGE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcompleted\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcompleted\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mAVERAGE_COMPLETED_PERCENTAGE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Calculate pending percentage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;34m'AVG_SCORE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;34m'MAX_SCORE'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AVERAGE_COMPLETED_PERCENTAGE' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Your existing DataFrame\n",
    "X = df[['PROGRAMNAME', 'TOTAL_TRAINERS', 'TOTAL_DAYS', 'AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE', 'AVG_SCORE', 'MAX_SCORE', 'MIN_SCORE', 'ASSESSMENT_COUNT']]\n",
    "y = df['TOTAL_HOURS']\n",
    "\n",
    "# Create dummy data for features\n",
    "dummy_data = {\n",
    "    'PROGRAMNAME': ['Program A', 'Program B', 'Program C', 'Program D', 'Program E','Program f', 'Program g', 'Program h', 'Program I', 'Program J'],\n",
    "    'TOTAL_TRAINERS': [random.randint(1, 5) for _ in range(10)],\n",
    "    'TOTAL_DAYS': [random.randint(1, 5) for _ in range(10)],\n",
    "    'AVERAGE_COMPLETED_PERCENTAGE': [random.uniform(0, 100) for _ in range(10)],\n",
    "    'AVERAGE_PENDING_PERCENTAGE': [100 - completed for completed in AVERAGE_COMPLETED_PERCENTAGE],  # Calculate pending percentage\n",
    "    'AVG_SCORE': [random.uniform(0, 100) for _ in range(10)],\n",
    "    'MAX_SCORE': [random.uniform(0, 100) for _ in range(10)],\n",
    "    'MIN_SCORE': [random.uniform(0, 100) for _ in range(10)],\n",
    "    'ASSESSMENT_COUNT': [random.randint(1, 50) for _ in range(10)],\n",
    "    'TOTAL_HOURS':[random.randint(1, 10) for _ in range(10)]\n",
    "}\n",
    "\n",
    "# Convert dummy data to DataFrame\n",
    "dummy_df = pd.DataFrame(dummy_data)\n",
    "\n",
    "# Concatenate the existing DataFrame with the dummy DataFrame\n",
    "df = pd.concat([X, dummy_df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1118, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       PROGRAMNAME  TOTAL_TRAINERS  TOTAL_DAYS  \\\n",
      "0        Data Science Fundamentals               1           2   \n",
      "1        Advanced Machine Learning               1           7   \n",
      "2          UI/UX Design Essentials               1           3   \n",
      "3     Backend Development Bootcamp               1           4   \n",
      "4     Cloud Computing Fundamentals               1           9   \n",
      "...                            ...             ...         ...   \n",
      "2113                   Program 400               3           4   \n",
      "2114                   Program 507               5           5   \n",
      "2115                   Program 233               4           1   \n",
      "2116                   Program 735               3           3   \n",
      "2117                   Program 188               4           5   \n",
      "\n",
      "      AVERAGE_HOURS_PER_SESSION  AVERAGE_DAYS_PER_SESSION  \\\n",
      "0                     16.000000                  2.000000   \n",
      "1                     56.000000                  7.000000   \n",
      "2                     24.000000                  3.000000   \n",
      "3                     32.000000                  4.000000   \n",
      "4                     24.000000                  3.000000   \n",
      "...                         ...                       ...   \n",
      "2113                   2.793771                  2.750327   \n",
      "2114                   1.693959                  2.396626   \n",
      "2115                   4.166316                  3.785512   \n",
      "2116                   1.816073                  1.460754   \n",
      "2117                   1.681685                  2.139408   \n",
      "\n",
      "      AVERAGE_COMPLETED_PERCENTAGE  AVERAGE_PENDING_PERCENTAGE  AVG_SCORE  \\\n",
      "0                       100.000000                    0.000000  81.000000   \n",
      "1                       100.000000                    0.000000  81.000000   \n",
      "2                       100.000000                    0.000000  37.000000   \n",
      "3                       100.000000                    0.000000  84.000000   \n",
      "4                       100.000000                    0.000000  73.000000   \n",
      "...                            ...                         ...        ...   \n",
      "2113                     37.204165                   47.568975   7.714530   \n",
      "2114                     46.154654                    1.119762  26.716616   \n",
      "2115                     67.364757                   46.078551  72.249806   \n",
      "2116                     70.087518                   48.182907  59.932754   \n",
      "2117                      6.110827                   63.335158  10.412118   \n",
      "\n",
      "      MAX_SCORE  MIN_SCORE  ASSESSMENT_COUNT  TOTAL_HOURS  \n",
      "0     81.000000  81.000000                 1          NaN  \n",
      "1     81.000000  81.000000                 1          NaN  \n",
      "2     37.000000  37.000000                 1          NaN  \n",
      "3     84.000000  84.000000                 1          NaN  \n",
      "4     93.000000  33.000000                 3          NaN  \n",
      "...         ...        ...               ...          ...  \n",
      "2113  40.233697  13.185932                19          9.0  \n",
      "2114  25.861877  27.458573                 6          7.0  \n",
      "2115  95.043684   8.177958                43          4.0  \n",
      "2116  38.373235  57.233909                37          3.0  \n",
      "2117  49.579884  56.612461                 2          2.0  \n",
      "\n",
      "[2118 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Your existing DataFrame\n",
    "X = df[['PROGRAMNAME', 'TOTAL_TRAINERS', 'TOTAL_DAYS', 'AVERAGE_HOURS_PER_SESSION', 'AVERAGE_DAYS_PER_SESSION', 'AVERAGE_COMPLETED_PERCENTAGE', 'AVERAGE_PENDING_PERCENTAGE', 'AVG_SCORE', 'MAX_SCORE', 'MIN_SCORE', 'ASSESSMENT_COUNT']]\n",
    "y = df['TOTAL_HOURS']\n",
    "\n",
    "# Generate unique program names\n",
    "unique_programs = ['Program {}'.format(i) for i in range(1, 1001)]\n",
    "\n",
    "# Create dummy data for features\n",
    "dummy_data = {\n",
    "    'PROGRAMNAME': [random.choice(unique_programs) for _ in range(1000)],\n",
    "    'TOTAL_TRAINERS': [random.randint(1, 5) for _ in range(1000)],\n",
    "    'TOTAL_DAYS': [random.randint(1, 5) for _ in range(1000)],\n",
    "    'AVERAGE_HOURS_PER_SESSION': [random.uniform(1, 5) for _ in range(1000)],\n",
    "    'AVERAGE_DAYS_PER_SESSION': [random.uniform(1, 5) for _ in range(1000)],\n",
    "    'AVERAGE_COMPLETED_PERCENTAGE': [random.uniform(0, 100) for _ in range(1000)],\n",
    "    'AVERAGE_PENDING_PERCENTAGE': [random.uniform(0, 100) for _ in range(1000)],\n",
    "    'AVG_SCORE': [random.uniform(0, 100) for _ in range(1000)],\n",
    "    'MAX_SCORE': [random.uniform(0, 100) for _ in range(1000)],\n",
    "    'MIN_SCORE': [random.uniform(0, 100) for _ in range(1000)],\n",
    "    'ASSESSMENT_COUNT': [random.randint(1, 50) for _ in range(1000)],\n",
    "    'TOTAL_HOURS':[random.randint(1, 10) for _ in range(1000)]\n",
    "}\n",
    "\n",
    "# Convert dummy data to DataFrame\n",
    "dummy_df = pd.DataFrame(dummy_data)\n",
    "\n",
    "# Concatenate the existing DataFrame with the dummy DataFrame\n",
    "df = pd.concat([X, dummy_df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

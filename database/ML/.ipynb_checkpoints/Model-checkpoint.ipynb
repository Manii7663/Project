{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Name  Trainers  Trainer_Experience  Total_Hours  \\\n",
      "0                          Swift         2                   5            6   \n",
      "1                          MySQL         3                   4            9   \n",
      "2                          MySQL         4                   8            1   \n",
      "3                   Cryptography         2                   2            8   \n",
      "4                  Accessibility         4                   7            9   \n",
      "..                           ...       ...                 ...          ...   \n",
      "995       Deep Learning Concepts         4                   7            2   \n",
      "996                        CI/CD         5                   5            6   \n",
      "997         Statistical Analysis         5                   9           10   \n",
      "998                 Cryptography         4                   1            1   \n",
      "999  Behavior-Driven Development         5                   7            9   \n",
      "\n",
      "     Total_Trainee  Difficulty_Level_encoded  \n",
      "0               20                         0  \n",
      "1               80                         0  \n",
      "2               40                         2  \n",
      "3               20                         1  \n",
      "4               40                         2  \n",
      "..             ...                       ...  \n",
      "995             40                         2  \n",
      "996             50                         2  \n",
      "997             50                         1  \n",
      "998             40                         2  \n",
      "999             50                         1  \n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"ml_data.csv\")\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the \"Difficulty_Level\" column\n",
    "df[\"Difficulty_Level_encoded\"] = label_encoder.fit_transform(df[\"Difficulty_Level\"])\n",
    "\n",
    "# Drop the original \"Difficulty_Level\" column\n",
    "df.drop(columns=[\"Difficulty_Level\"], inplace=True)\n",
    "\n",
    "# Display the encoded DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                        77\n",
       "Trainers                     5\n",
       "Trainer_Experience          10\n",
       "Total_Hours                 10\n",
       "Total_Trainee                8\n",
       "Difficulty_Level_encoded     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Trainers', 'Trainer_Experience', 'Total_Hours',\n",
       "       'Total_Trainee', 'Difficulty_Level_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Difficulty_Level_Encoded'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f9287586281a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Separate features and target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Trainers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Trainer_Experience'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Total_Trainee'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Difficulty_Level_Encoded'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Total_Hours'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5780\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5782\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5784\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5844\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5845\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5847\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Difficulty_Level_Encoded'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Assume df1 is your preprocessed DataFrame with features and target column 'SCOREACHIEVEDINQUIZ'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[['Name', 'Trainers', 'Trainer_Experience','Total_Trainee', 'Difficulty_Level_Encoded']]\n",
    "y = df['Total_Hours']\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Handle NaN values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X_encoded), columns=X_encoded.columns)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42),\n",
    "    'Support Vector Regressor': SVR(),\n",
    "    'Neural Network (MLPRegressor)': MLPRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{name}: Mean Squared Error = {mse}\")\n",
    "\n",
    "# You can also perform cross-validation to get more reliable estimates of model performance\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_imputed, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mse_mean = -scores.mean()\n",
    "    print(f\"{name}: Cross-validated Mean Squared Error = {mse_mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 9.658375248797238\n",
      "Accuracy: 63.5 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assume df1 is your preprocessed DataFrame with features and target column 'ASSESSMENT_COMPLETION_TIME_IN_HOURS'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[['Name', 'Trainers', 'Trainer_Experience','Total_Trainee', 'Difficulty_Level_basic', 'Difficulty_Level_hard','Difficulty_Level_medium']]\n",
    "y = df['Total_Hours']\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = pd.get_dummies(X)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Handle NaN values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X_encoded), columns=X_encoded.columns)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = linear_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "threshold = 2\n",
    "\n",
    "# Convert regression predictions to binary classification labels\n",
    "y_pred_binary = (y_pred <= threshold).astype(int)\n",
    "y_test_binary = (y_test <= threshold).astype(int)\n",
    "\n",
    "# Calculate accuracy for binary classification\n",
    "accuracy = (y_pred_binary == y_test_binary).mean()\n",
    "\n",
    "print(f\"Accuracy: {accuracy*100} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Completion Time: 332282312316 hrs\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define dummy values for features\n",
    "dummy_data={\n",
    "    'Name': ['MySql'],\n",
    "    'Trainers': [6],\n",
    "    'Trainer_Experience': [4],\n",
    "    'Total_Trainee': [40],\n",
    "    'Difficulty_Level_Encoded': [1]\n",
    "}\n",
    "    \n",
    "\n",
    "# Create DataFrame with dummy values\n",
    "dummy_df = pd.DataFrame(dummy_data)\n",
    "\n",
    "# Get the list of feature names used during training\n",
    "training_feature_names = X_imputed.columns.tolist()\n",
    "\n",
    "# Ensure that the dummy DataFrame has the same columns as training data\n",
    "dummy_df = pd.get_dummies(dummy_df)\n",
    "dummy_df = dummy_df.reindex(columns=training_feature_names, fill_value=0)\n",
    "\n",
    "# Handle NaN values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "dummy_imputed = pd.DataFrame(imputer.fit_transform(dummy_df), columns=dummy_df.columns)\n",
    "\n",
    "# Make prediction\n",
    "prediction = linear_regressor.predict(dummy_imputed)\n",
    "\n",
    "# Print prediction\n",
    "print(\"Predicted Completion Time:\", int(prediction[0]) ,'hrs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

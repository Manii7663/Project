{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566aec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f6ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pymongo\n",
    "import snowflake.connector\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876864f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a293682",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_connection_string =  \"mongodb+srv://manii:1234@cluster0.bditt1m.mongodb.net/project?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "# Snowflake connection settings\n",
    "SNOWFLAKE_ACCOUNT = \"lx16664.central-india.azure\"\n",
    "SNOWFLAKE_USER = \"mani\"\n",
    "SNOWFLAKE_PASSWORD = \"Jman@600113\"\n",
    "SNOWFLAKE_DATABASE = \"TrainingProject\"\n",
    "SNOWFLAKE_SCHEMA = \"PROJECT\"\n",
    "SNOWFLAKE_WAREHOUSE = \"COMPUTE_WH\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d8c641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB Atlas successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # Connect to MongoDB Atlas\n",
    "    mongo_client = pymongo.MongoClient(mongo_connection_string)\n",
    "    mongo_db = mongo_client[ 'project']\n",
    "    \n",
    "    # Print connection success message\n",
    "    print(\"Connected to MongoDB Atlas successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with mongo_client and mongo_db\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to MongoDB Atlas: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171c4f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to Snowflake using environment variables\n",
    "\n",
    "\n",
    "    snowflake_conn = snowflake.connector.connect(\n",
    "    user=SNOWFLAKE_USER,\n",
    "    password=SNOWFLAKE_PASSWORD,\n",
    "    account=SNOWFLAKE_ACCOUNT,\n",
    "    warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "    database=SNOWFLAKE_DATABASE,\n",
    "    schema=SNOWFLAKE_SCHEMA\n",
    ")\n",
    "\n",
    "    # Print connection success message\n",
    "    print(\"Connected to Snowflake successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with snowflake_conn\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to Snowflake: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9f9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5515b07a",
   "metadata": {},
   "source": [
    "## Mongo to Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f437af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from collection 'trainingprograms' written to 'staging_raw_data/trainingprograms.csv'\n",
      "Data from collection 'batches' written to 'staging_raw_data/batches.csv'\n",
      "Data from collection 'users' written to 'staging_raw_data/users.csv'\n",
      "Data from collection 'trainingsessions' written to 'staging_raw_data/trainingsessions.csv'\n",
      "Data from collection 'coes' written to 'staging_raw_data/coes.csv'\n",
      "Data from collection 'assessmentscores' written to 'staging_raw_data/assessmentscores.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create raw_data folder if it doesn't exist\n",
    "if not os.path.exists(\"staging_raw_data\"):\n",
    "    os.makedirs(\"staging_raw_data\")\n",
    "\n",
    "# Iterate over each collection\n",
    "for collection_name in mongo_db.list_collection_names():\n",
    "    # Retrieve data from collection\n",
    "    collection_data = list(mongo_db[collection_name].find())\n",
    "    \n",
    "    # Convert data to DataFrame\n",
    "    df = pd.DataFrame(collection_data)\n",
    "    \n",
    "    # Write DataFrame to CSV file\n",
    "    csv_file_path = f\"staging_raw_data/{collection_name}.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Data from collection '{collection_name}' written to '{csv_file_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "651aafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close MongoDB connection\n",
    "mongo_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4192438",
   "metadata": {},
   "source": [
    "## Ingest Into Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa84fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 'assessmentscores.csv' inserted into 'assessmentscores' table in Snowflake.\n",
      "Data from 'batches.csv' inserted into 'batches' table in Snowflake.\n",
      "Data from 'coes.csv' inserted into 'coes' table in Snowflake.\n",
      "Data from 'trainingprograms.csv' inserted into 'trainingprograms' table in Snowflake.\n",
      "Data from 'trainingsessions.csv' inserted into 'trainingsessions' table in Snowflake.\n",
      "Data from 'users.csv' inserted into 'users' table in Snowflake.\n"
     ]
    }
   ],
   "source": [
    "def sanitize_name(name):\n",
    "    # Replace invalid characters with underscores\n",
    "    return ''.join(c if c.isalnum() else '_' for c in name)\n",
    "if not os.path.exists(\"staging_raw_data\"):\n",
    "    print(\"No data to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Iterate over each CSV file in the staging_raw_data folder\n",
    "for filename in os.listdir(\"staging_raw_data\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Extract table name from filename (remove .csv extension) and sanitize it\n",
    "        table_name = sanitize_name(os.path.splitext(filename)[0])\n",
    "        \n",
    "        # Read CSV file into DataFrame\n",
    "        df = pd.read_csv(f\"staging_raw_data/{filename}\")\n",
    "        \n",
    "        # Replace NaN values with empty strings\n",
    "        df = df.fillna('')\n",
    "        \n",
    "        # Convert all data to string\n",
    "        df = df.astype(str)\n",
    "        \n",
    "        # Create table in Snowflake if it doesn't exist\n",
    "        snowflake_cursor = snowflake_conn.cursor()\n",
    "        \n",
    "        # Drop the table if it exists\n",
    "        snowflake_cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        \n",
    "        # Create the table\n",
    "        create_table_query = f\"CREATE TABLE {table_name} (\"\n",
    "        for column in df.columns:\n",
    "            # Sanitize column names\n",
    "            safe_column_name = sanitize_name(column)\n",
    "            create_table_query += f'{safe_column_name} VARCHAR,'\n",
    "        create_table_query = create_table_query[:-1] + \")\"  # Remove trailing comma\n",
    "        snowflake_cursor.execute(create_table_query)\n",
    "        \n",
    "        # Prepare INSERT INTO statement\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({','.join(['%s'] * len(df.columns))})\"\n",
    "        \n",
    "        # Convert DataFrame to list of tuples (rows)\n",
    "        rows = [tuple(row) for row in df.itertuples(index=False)]\n",
    "        \n",
    "        # Execute bulk insert\n",
    "        snowflake_cursor.executemany(insert_query, rows)\n",
    "        snowflake_cursor.close()\n",
    "        \n",
    "        print(f\"Data from '{filename}' inserted into '{table_name}' table in Snowflake.\")\n",
    "\n",
    "# Commit the transaction\n",
    "snowflake_conn.commit()\n",
    "\n",
    "# Close Snowflake connection\n",
    "snowflake_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b252f541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe552f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42831d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
